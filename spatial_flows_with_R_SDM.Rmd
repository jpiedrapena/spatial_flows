---
title: "Spatial Flows Modelling with **R**"
author: "T. Laurent, P. Margaretic, C. Thomas-Agnan"
date: "August 12, 2019"
output:
  html_document:
    highlight: tango
    number_sections: yes
    toc: yes
    toc_depth: 2
---
<link href="markdown7.css" rel="stylesheet">

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Packages needed:

```{r, eval = F}
install.packages("devtools")
install.packages(c("cartography", "Matrix", "rgdal", 
                   "spdep", "tidyverse", "maptools", "spatialreg"))
```

```{r, message = F}
require("cartography")# representation of spatial data
require("Matrix")     # sparse matrix
require("rgdal")      # import spatial data
require("spdep")      # spatial econometrics modelling
require("tidyverse")  # tidyverse data
require("maptools")   # spatial 
```


# Data preparation #

LeSage and Pace (2008)  present the spatial interaction model specification (eq. 20) for modelling origin destination flows :

$$(I_{N\times N}-\rho_dW_dy-\rho_oW_oy-\rho_wW_wy)Y = \alpha \iota_N + X_d\beta_d+X_o\beta_o + XL_d\delta_d + XL_o\delta_o + \gamma G+\epsilon $$
One example of application is the analysis of home to work commuting flows. In the spatial econometrics litterature, the origin and destination locations coincide.  In our paper, we propose to extend this model to the case where the locations at origin and destinations do not coincide. This can happen in geomarketing applications where the locations of the origins are the customers and the locations at destinations are the spatial coordinates of the states. 

## Data storage 

Let $n_o$ be the number of geographical sites at the origin and $n_d$ the number of geographical sites at destination. We denote by $Y_{ij}$ the flow which represents a quantity moving from a geographical site $i$ ($i=i_1,...,i_{n_o}$) towards a geographical site $j$ ($j=j_1...j_{n_d}$). Let $N=n_on_d$. We also denote by $G_{ij}$ the distance between site $i$ and site $j$. Usually, the list of origins and destinations coincide which simplifies the notation because in that case $i_1=j_1=1$, ..., $i_{n_o}=j_{n_d}=n$. In that particular case, we observe the same characteristics $x$ at origin and destination. When the list of origins and destinations are not the same, this complicates the notation because the variables observed at origin and destination may be different. Thus, we should note $x$ the variables observed at the origin and $z$ the variables observed at destination. 

### Dependent and distance variable

To store the dependent variable and the distances, the user has two options:

* Flows and distances  are stored into matrices of size $n_o \times n_d$,

* Flows and distances are stored into vectors of size $N$.

### Explanatory variables 

To store the explanatory variables, the user also has two options:

* Explanatory variables $x$ observed at origin (respectively $z$ at destination) are stored into a **data.frame** of size $n_o\times R_o$ (resp. $n_d\times R_d$) where $R_o$ (resp. $R_d$) are the respective numbers of explanatory variables. 

* Explanatory variables observed at origin and destination are stored into a **data.frame** of size $n_on_d\times (R_o + R_d)$. To obtain this form, the user has to use a kronecker product applied to $x$ and $z$.  


### Spatial weight matrices

We denote by $OW$ (resp. $DW$) the spatial weight matrix of size $n_o\times n_o$ (resp. $n_d\times n_d$) which determine if two locations at origin (resp. destination) are neighbours.  

To build spatial matrices $W_o$, $W_d$ or $W_w$ of size $N \times N$ the user can use the properties of kronecker products and the spatial weight matrices $OW$ and $DW$. He can also use the properties of sparse matrices.  


### Sparse simulated data example

We will consider two cases: the case where the list of origins and destinations coincide and the case where it does not coincide. 

#### List of origins and destinations coincide 

We consider three examples with different numbers of observations. We use examples from  https://ialab.it.monash.edu/~dwyer/papers/maptrix.pdf. We define the polygons by using the function *create_grid()* inspired by the example given by R. Bivand in https://stat.ethz.ch/pipermail/r-sig-geo/2009-December/007163.html. We consider one explanatory variable for each data set. The programs to obtain these simulated examples are in "simulated_examples.R. For Australia, we also used real data obtained from the Australian Bureau of Statistics (https://itt.abs.gov.au/itt/r.jsp?databyregion).

```{r}
source("R/simulated_examples.R")
```

* The first example is a simplification of the 8 main regions of Australia.

```{r, echo = F, fig = T}
#pdf("figures/spdf_au.pdf")
spplot(spdf_au, "x",
      panel = function(x,y,z,subscripts,...) {
        panel.polygonsplot(x,y,z,subscripts,...)
        sp.text(coordinates(spdf_au), row.names(spdf_au), cex = 0.8)
      } 
)
#dev.off()
```

* The second example is a simplification of the 16 main regions of Germany.

```{r, echo = F, fig = T}
#pdf("figures/spdf_ge.pdf")
spplot(spdf_ge, "x",
      panel = function(x,y,z,subscripts,...) {
        panel.polygonsplot(x,y,z,subscripts,...)
        sp.text(coordinates(spdf_ge), row.names(spdf_ge), cex = 0.8)
      } 
)
#dev.off()
```

* The third example is a simplification of the 51 main regions of the USA:

```{r, echo = F, fig = T}
#pdf("figures/spdf_usa.pdf")
spplot(spdf_usa, "x",
      panel = function(x,y,z,subscripts,...) {
        panel.polygonsplot(x,y,z,subscripts,...)
        sp.text(coordinates(spdf_usa), row.names(spdf_usa), cex = 0.8)
      } 
)
#dev.off()
```

<!-- * The fourth example is a grid of size $40 \times 25$ i.e. with 1000 regions -->

```{r, echo = F, eval = F, fig = T}
spplot(spdf_grid, "x")
```


##### Storing the variables into origin-destination format 

If user wants to store the explanatory variables in a matrix of size $N\times R$, he has to use the kronecker product. We present the results for the Australian regions. First, we create the **origin** and **dest** variables: 

```{r}
n_au <- nrow(spdf_au)
flows_au <- data.frame(origin = rep(row.names(spdf_au), 
                                    each = n_au),
                         dest = rep(row.names(spdf_au), n_au))
```

We create the destination data:

```{r}
flows_au_d <- sapply(spdf_au@data[, c("x", "wage", "pop", "age",
                                      "ln_wage", "ln_pop", "ln_age")], 
                     function (x) kronecker(rep(1, n_au), x))
colnames(flows_au_d) <- paste0(colnames(flows_au_d), "_d")
```

We create the origin data:

```{r}
flows_au_o <- sapply(spdf_au@data[, c("x", "wage", "pop", "age",
                                      "ln_wage", "ln_pop", "ln_age")], 
                     function (x) kronecker(x, rep(1, n_au)))
colnames(flows_au_o) <- paste0(colnames(flows_au_o), "_o")
```

We merge the data:

```{r}
flows_au <- cbind(flows_au, flows_au_d, flows_au_o)
head(flows_au)
```

If user wants to store the dependant variable from a matrix of size $n \times n$ to a vector of size $N$, he has to use the function *as.vector()*. He has to take care of the ordering of the observations:

```{r}
au_flows <- au_flows[id_region_au, id_region_au]
flows_au$real_Y <- as.vector(au_flows) 
```

Same has been done for Germany and USA.

```{r, echo = F}
n_ge <- nrow(spdf_ge)
flows_ge <- data.frame(origin = rep(row.names(spdf_ge), 
                                    each = n_ge),
                         dest = rep(row.names(spdf_ge), n_ge),
                       x_o = kronecker(spdf_ge$x, rep(1, n_ge)),
                       x_d = kronecker(rep(1, n_ge), spdf_ge$x))

n_usa <- nrow(spdf_usa)
flows_usa <- data.frame(origin = rep(row.names(spdf_usa), 
                                    each = n_usa),
                         dest = rep(row.names(spdf_usa), n_usa),
                       x_o = kronecker(spdf_usa$x, rep(1, n_usa)),
                       x_d = kronecker(rep(1, n_usa), spdf_usa$x))
```


##### Distances between locations

The distances between origins and destinations can be stored in a matrix of size $n \times n$.

```{r}
G_au <- as.matrix(log(1 + dist(coordinates(spdf_au))))
```

It can also be added to the **data.frame** which presents the data in vectorized form.

```{r}
flows_au$g <- as.vector(G_au)
```

Same has been done for Germany, USA and the simulated grid.

```{r, echo = F}
G_ge <- as.matrix(log(1 + dist(coordinates(spdf_ge))))
flows_ge$g <- as.vector(G_ge)
G_usa <- as.matrix(log(1 + dist(coordinates(spdf_usa))))
flows_usa$g <- as.vector(G_usa)
```


##### Construct the spatial weight matrices 

To define the spatial weight matrices for our geographical sites, we use the contiguity properties for Australia and Germany. Because some states in USA have no neighbours when using this method, we use the 4 nearest neighbours method for USA. All these methods have been implemented in package **sp** (Bivand et al., 2013).

```{r}
w_au_nb <- poly2nb(spdf_au)
w_au <- listw2mat(nb2listw(w_au_nb))
w_ge_nb <- poly2nb(spdf_ge)
w_ge <- listw2mat(nb2listw(w_ge_nb))
w_usa_nb <- knn2nb(knearneigh(coordinates(spdf_usa), k = 4))
w_usa <- listw2mat(nb2listw(w_usa_nb))
```

We represent the spatial links between the observations:

```{r, fig = T, fig.width=10, fig.height=6}
#pdf("figures/spdf_neighbors.pdf", width = 10, height = 5)
par(mfrow = c(1, 3))
plot(spdf_au)
plot(w_au_nb, coordinates(spdf_au), add = T)
plot(spdf_ge)
plot(w_ge_nb, coordinates(spdf_ge), add = T)
plot(spdf_usa)
plot(w_usa_nb, coordinates(spdf_usa), add = T)
#dev.off()
```

To build the spatial weight matrices $W_o$, $W_d$ and $W_w$, the user has to use Kronecker products. It can be interesting to use the properties of sparse matrices aw well to avoid to store too much data. For example we compare the memory needed to store $W_o$ with or without using the sparse properties:

```{r}
object.size(kronecker(diag(n_au), w_au))
object.size(kronecker(Diagonal(n_au), w_au))
```

```{r}
W_au_d <- kronecker(Diagonal(n_au), w_au)
W_au_o <- kronecker(w_au, Diagonal(n_au))
W_au_w <- kronecker(as(w_au, "Matrix"), w_au)
```

We prepare the lagged explanatory variables:

```{r}
flows_au$lagged_x_d <- as.matrix(W_au_d) %*% flows_au$x_d
flows_au[, c("lagged_wage_d", "lagged_pop_d", "lagged_age_d",
             "lagged_ln_wage_d", "lagged_ln_pop_d", "lagged_ln_age_d")] <- 
  as.matrix(W_au_d) %*% 
  as.matrix(flows_au[, c("wage_d", "pop_d", "age_d", 
                             "ln_wage_d", "ln_pop_d", "ln_age_d")])
flows_au$lagged_x_o <- as.matrix(W_au_o) %*% flows_au$x_o
flows_au[, c("lagged_wage_o", "lagged_pop_o", "lagged_age_o",
             "lagged_ln_wage_o", "lagged_ln_pop_o", "lagged_ln_age_o")] <- 
  as.matrix(W_au_o) %*% 
  as.matrix(flows_au[, c("wage_o", "pop_o", "age_o",
                             "ln_wage_o", "ln_pop_o", "ln_age_o")])
```

Same has been done  for Germany and USA.

```{r, echo = F}
W_ge_d <- kronecker(Diagonal(n_ge), w_ge)
W_ge_o <- kronecker(w_ge, Diagonal(n_ge))
W_ge_w <- kronecker(as(w_ge, "Matrix"), w_ge)
flows_ge$lagged_x_d <- as.matrix(W_ge_d) %*% flows_ge$x_d
flows_ge$lagged_x_o <- as.matrix(W_ge_o) %*% flows_ge$x_o

W_usa_d <- kronecker(Diagonal(n_usa), w_usa)
W_usa_o <- kronecker(w_usa, Diagonal(n_usa))
W_usa_w <- kronecker(as(w_usa, "Matrix"), w_usa)
flows_usa$lagged_x_d <- as.matrix(W_usa_d) %*% flows_usa$x_d
flows_usa$lagged_x_o <- as.matrix(W_usa_o) %*% flows_usa$x_o
```


#### List of origins and destinations do not coincide 

We consider the migration flows from countries of Africa towards countries in Europe. The data are extracted from https://journals.sagepub.com/doi/suppl/10.1177/0022002718823907 

To load the data:
```{r}
source("./R/migration_data.R")
```


```{r, fig = T, fig.width=5, fig.height=8, message = F, warning = F}
pdf("figures/grid.pdf", width = 7, height = 8)
plot(st_geometry(europe), xlim = c(-40, 60), ylim = c(-40, 70))
plot(st_geometry(africa), add = T)
dev.off()
```

##### Transform the explanatory variables to origin-destination format 

To store the explanatory variables in a matrix of size $N\times R$, the user has to use Kronecker products separetly for origins and for destinations : 

```{r}
n_mig_o <- nrow(africa)
n_mig_d <- nrow(europe)
x_mig_origin <- kronecker(as.matrix(africa %>% 
                  dplyr::select(popul_o, gdp_o, civilconflict_o)  %>%
                  st_drop_geometry()), rep(1, n_mig_d))
colnames(x_mig_origin) <- c("popul_o", "gdp_o", "civilconflict_o")
x_mig_dest <- kronecker(rep(1, n_mig_o), as.matrix(europe %>% 
                  dplyr::select(popul_d, gdp_d)  %>%
                  st_drop_geometry()))
colnames(x_mig_dest) <- c("popul_d", "gdp_d")
flows_mig <- data.frame(origin = rep(africa$NOM, 
                                    each = n_mig_d),
                         dest = rep(europe$NOM, n_mig_o),
                         x_mig_origin,
                        x_mig_dest)
head(flows_mig)
```

##### Distances between locations

The distances between flows can be presented in a matrix of size $n_d \times n_o$. We use the function *gDistance()* from package **rgeos** (Bivand and Rundel, 2019). 

```{r}
G_mig <- st_distance(st_centroid(africa), 
                      st_centroid(europe))
```

It can be also added to the data.frame which presents the data in vectorized form

```{r}
flows_mig$g <- as.vector(t(G_mig))
```

We also add the dependent variable 

```{r}
flows_mig$y <- as.vector(Y_mig)
```

##### Construct the spatial weight matrices 

To define the spatial weight matrix on our geographical sites, we use the 4-nearest neighbours properties for origins and destinations.

```{r}
w_mig_o_nb <- knn2nb(knearneigh(as(st_centroid(africa), "Spatial"), k = 4))
w_mig_o <- listw2mat(nb2listw(w_mig_o_nb))
w_mig_d_nb <- knn2nb(knearneigh(as(st_centroid(europe), "Spatial"), k = 4))
w_mig_d <- listw2mat(nb2listw(w_mig_d_nb))
```

To build the spatial weight matrices $W_o$, $W_d$ and $W_w$, the user has to use Kronecker products. 

```{r}
W_mig_d <- kronecker(Diagonal(n_mig_o), w_mig_d)
W_mig_o <- kronecker(w_mig_o, Diagonal(n_mig_d))
W_mig_w <- W_mig_o %*% W_mig_d
```

We prepare the lagged explanatory variables:

```{r}
flows_mig[, c("lagged_popul_d", "lagged_gdp_d")] <- 
  as.matrix(W_mig_d) %*% as.matrix(flows_mig[, c("popul_d", "gdp_d")])
flows_mig[, c("lagged_popul_o", "lagged_gdp_o", "lagged_civilconflict_o")] <- 
  as.matrix(W_mig_d) %*% as.matrix(flows_mig[, c("popul_o", "gdp_o",
                                                 "civilconflict_o")])
```


### DGP of the $Y$ variables ###

#### Intraregional modelling 

Laurent, Margaretic and Thomas-Agnan (2019) proposes the spatial interaction model specification for modelling origin destination flows :

$$(I_{N\times N}-\rho_dW_dy-\rho_oW_oy-\rho_wW_wy)Y = \iota_N\alpha + vec(I_n)\alpha_i + X_d\beta_d+X_o\beta_o+X_i\beta_i + XL_d\delta_d + XL_o\delta_o + \gamma G+\epsilon $$

The previously described procedure aims at allowing the coefficients associated with
the matrices $X_d$, $X_o$ to more accurately reflect the variation in interregional flows, and those associated with the matrix $X_i$ to capture intraregional variation in flows.

Same has been done for Germany and USA.

```{r}
flows_au_od <- flows_au
flows_au$vec_In <- as.vector(diag(n_au))

for (var in c("x", "wage", "pop", "age", 
              "lagged_x", "lagged_wage", "lagged_pop", "lagged_age",
              "ln_wage", "ln_pop", "ln_age", 
              "lagged_ln_wage", "lagged_ln_pop", "lagged_ln_age")) {
  flows_au[, paste0(var, "_i")] <- flows_au[, paste0(var, "_o")]
  flows_au[flows_au$origin != flows_au$dest, paste0(var, "_i")] <- 0
  flows_au[flows_au$origin == flows_au$dest, paste0(var, "_o")] <- 0
  flows_au[flows_au$origin == flows_au$dest, paste0(var, "_d")] <- 0
}
```


```{r, echo = F}
flows_ge_od <- flows_ge
flows_ge$vec_In <- as.vector(diag(n_ge))
flows_usa_od <- flows_usa
flows_usa$vec_In <- as.vector(diag(n_usa))

for (var in c("x", "lagged_x")) {
  flows_ge[, paste0(var, "_i")] <- flows_ge[, paste0(var, "_o")]
  flows_ge[flows_ge$origin != flows_ge$dest, paste0(var, "_i")] <- 0
  flows_ge[flows_ge$origin == flows_ge$dest, paste0(var, "_o")] <- 0
  flows_ge[flows_ge$origin == flows_ge$dest, paste0(var, "_d")] <- 0
  
  flows_usa[, paste0(var, "_i")] <- flows_usa[, paste0(var, "_o")]
  flows_usa[flows_usa$origin != flows_usa$dest, paste0(var, "_i")] <- 0
  flows_usa[flows_usa$origin == flows_usa$dest, paste0(var, "_o")] <- 0
  flows_usa[flows_usa$origin == flows_usa$dest, paste0(var, "_d")] <- 0
}
```



We simulate 9 different SDM interaction models: 

$y_9 = (I_{N}-\rho_oW_o-\rho_dW_d+\rho_wW_w)^{-1}(Z\delta + \epsilon)$,

$y_8 = (I_{N}-\rho_oW_o-\rho_dW_d+\rho_d \rho_oW_w)^{-1}(Z\delta + \epsilon)$,

$y_7 = (I_{N}-\rho_oW_o-\rho_dW_d)^{-1}(Z\delta + \epsilon)$,

$y_6 = (I_{N}-\rho_{odw}(W_o + W_d + W_w)/3)^{-1}(Z\delta + \epsilon)$,

$y_5 = (I_{N}-\rho_{od}(W_o + W_d)/2)^{-1}(Z\delta + \epsilon)$,

$y_4 = (I_{N}-\rho_wW_w)^{-1}(Z\delta + \epsilon)$,

$y_3 = (I_{N}-\rho_oW_o)^{-1}(Z\delta + \epsilon)$,

$y_2 = (I_{N}-\rho_dW_d)^{-1}(Z\delta + \epsilon)$,

$y_1 = (Z\delta + \epsilon)$,

with $Z=(1_{N}, vec(I_n), X_d, X_o, X_i, lagged(X_d), lagged(X_o), lagged(X_i), G)$, $\delta = (\alpha, \beta_d, \beta_o, \beta_i, \delta_d, \delta_o,  \delta_i, \gamma)$. We generate a set of flows $Y$ with $\alpha = 1$, $\alpha_i = 0.5$, $\beta_d = 1$, $\beta_o = 0.5$, $\beta_i=2$, $\delta_d = 0.25$, $\delta_o = 0.1$, $\delta_i = 0.5$, $\gamma = -2.0$, $\rho_d = 0.4$, $\rho_o = 0.4$, and $\rho_w = -0.16$.

```{r}
delta <- c(2, 1.5, 1, 0.5, 2.5, 0.25, 0.1, 0.5, -2)
rho <- c(0.4, 0.4, -0.16)
```

We consider one simulation for the model for the case "intra":
```{r}
Z_au <- cbind(1, flows_au$vec_In, 
              flows_au$x_d, flows_au$x_o, flows_au$x_i,
              flows_au$lagged_x_d, flows_au$lagged_x_o, flows_au$lagged_x_i,
              flows_au$g)
```

We consider another simulation for the model for the case without "intra". Because the origin and destination are different in the intra case, we have to consider antother matrix:

```{r}
Z_au_od <- cbind(1, flows_au_od$x_d, flows_au_od$x_o, 
              flows_au_od$lagged_x_d, flows_au_od$lagged_x_o,
              flows_au_od$g)
```

Flows can be presented in vectorized format. For this, we use the function *DGP_flow_sdm()* which allows to simulate flows data.

```{r}
source("./R/DGP_flow_sdm.R")
```

```{r, echo = F}
source("./R/powerWeights.R")
```


The function *DGP_flow_sdm()* takes as arguments:
```{bash, eval = F}
DGP_flow_sdm(z, delta, rho, W_d, W_o, W_w,
             seed = NULL, sigma = 1, message = F)
```

* **z**, the matrix containing the explanatory variables,
* **delta**, the vector of parameters,
* **rho**, the vector with $(\rho_d,\rho_o,\rho_w)$
* **W_o**, **W_d**, **W_w** the spatial weight matrices of size $N\times N$
* **seed**, a vector of integer values for the seed. NULL by default 
* **sigma**, the variance of the residuals
* **message**, print a message to indicate the ratio of sd(noise)/sd(signal). 
* **model**, a character. 

```{r}
flows_au[, "y_9"] <- DGP_flow_sdm(z = Z_au, delta = delta,  rho = rho,
               W_d = as.matrix(W_au_d), 
               W_o = as.matrix(W_au_o), 
               W_w = as.matrix(W_au_w), 
               seed = 123, sigma = 1, message = T,
               model = "model_9")

flows_au[, "y_8"] <- DGP_flow_sdm(z = Z_au, delta = delta,  rho = rho[1:2],
               W_d = as.matrix(W_au_d), 
               W_o = as.matrix(W_au_o), 
               W_w = as.matrix(W_au_w), 
               seed = 123, sigma = 1, message = T,
               model = "model_8")

flows_au[, "y_7"] <- DGP_flow_sdm(z = Z_au, delta = delta,  rho = rho[1:2],
               W_d = as.matrix(W_au_d), 
               W_o = as.matrix(W_au_o), 
               seed = 123, sigma = 1, message = T,
               model = "model_7")

flows_au[, "y_6"] <- DGP_flow_sdm(z = Z_au, delta = delta,  rho = rho[1],
               W_d = as.matrix(W_au_d), 
               W_o = as.matrix(W_au_o),
               W_w = as.matrix(W_au_w), 
               seed = 123, sigma = 1, message = T,
               model = "model_6")

flows_au[, "y_5"] <- DGP_flow_sdm(z = Z_au, delta = delta,  rho = rho[1],
               W_d = as.matrix(W_au_d), 
               W_o = as.matrix(W_au_o),
               seed = 123, sigma = 1, message = T,
               model = "model_5")

flows_au[, "y_4"] <- DGP_flow_sdm(z = Z_au, delta = delta,  rho = rho[1],
               W_w = as.matrix(W_au_w), 
               seed = 123, sigma = 1, message = T,
               model = "model_4")

flows_au[, "y_3"] <- DGP_flow_sdm(z = Z_au, delta = delta,  rho = rho[1],
               W_o = as.matrix(W_au_o), 
               seed = 123, sigma = 1, message = T,
               model = "model_3")

flows_au[, "y_2"] <- DGP_flow_sdm(z = Z_au, delta = delta,  rho = rho[1],
               W_d = as.matrix(W_au_d), 
               seed = 123, sigma = 1, message = T,
               model = "model_2")

flows_au[, "y_1"] <- DGP_flow_sdm(z = Z_au, delta = delta,
               seed = 123, sigma = 1, message = T,
               model = "model_1")

flows_au_od[, "y_1"] <- DGP_flow_sdm(z = Z_au_od, delta = delta[-c(2, 5, 8)],
               seed = 123, sigma = 1, message = T,
               model = "model_1")
```

The data set corresponding to the vectorized flows is presented in that form :

```{r}
head(flows_au)
```
Flows can be also be presented in matrix format. 

```{r}
Y_au_9 <- matrix(flows_au$y_9, n_au, n_au)
Y_au_8 <- matrix(flows_au$y_8, n_au, n_au)
Y_au_7 <- matrix(flows_au$y_7, n_au, n_au)
Y_au_6 <- matrix(flows_au$y_6, n_au, n_au)
Y_au_5 <- matrix(flows_au$y_5, n_au, n_au)
Y_au_4 <- matrix(flows_au$y_4, n_au, n_au)
Y_au_3 <- matrix(flows_au$y_3, n_au, n_au)
Y_au_2 <- matrix(flows_au$y_2, n_au, n_au)
Y_au_1 <- matrix(flows_au$y_1, n_au, n_au)
Y_au_od_1 <- matrix(flows_au_od$y_1, n_au, n_au)
```


Same has been done for Germany, USA and the grid examples.

```{r, echo = F}
Z_ge <- cbind(1, flows_ge$vec_In, 
              flows_ge$x_d, flows_ge$x_o, flows_ge$x_i,
              flows_ge$lagged_x_d, flows_ge$lagged_x_o, flows_ge$lagged_x_i,
              flows_ge$g)

Z_ge_od <- cbind(1, flows_ge_od$x_d, flows_ge_od$x_o, 
              flows_ge_od$lagged_x_d, flows_ge_od$lagged_x_o, 
              flows_ge_od$g)

flows_ge[, "y_9"] <- DGP_flow_sdm(z = Z_ge, delta = delta,  rho = rho,
               W_d = as.matrix(W_ge_d), 
               W_o = as.matrix(W_ge_o), 
               W_w = as.matrix(W_ge_w), 
               seed = 123, sigma = 1, message = F,
               model = "model_9")

flows_ge[, "y_8"] <- DGP_flow_sdm(z = Z_ge, delta = delta,  rho = rho[1:2],
               W_d = as.matrix(W_ge_d), 
               W_o = as.matrix(W_ge_o), 
               W_w = as.matrix(W_ge_w), 
               seed = 123, sigma = 1, message = F,
               model = "model_8")

flows_ge[, "y_7"] <- DGP_flow_sdm(z = Z_ge, delta = delta,  rho = rho[1:2],
               W_d = as.matrix(W_ge_d), 
               W_o = as.matrix(W_ge_o), 
               seed = 123, sigma = 1, message = F,
               model = "model_7")

flows_ge[, "y_6"] <- DGP_flow_sdm(z = Z_ge, delta = delta,  rho = rho[1],
               W_d = as.matrix(W_ge_d), 
               W_o = as.matrix(W_ge_o),
               W_w = as.matrix(W_ge_w), 
               seed = 123, sigma = 1, message = F,
               model = "model_6")

flows_ge[, "y_5"] <- DGP_flow_sdm(z = Z_ge, delta = delta,  rho = rho[1],
               W_d = as.matrix(W_ge_d), 
               W_o = as.matrix(W_ge_o),
               seed = 123, sigma = 1, message = F,
               model = "model_5")

flows_ge[, "y_4"] <- DGP_flow_sdm(z = Z_ge, delta = delta,  rho = rho[1],
               W_w = as.matrix(W_ge_w), 
               seed = 123, sigma = 1, message = F,
               model = "model_4")

flows_ge[, "y_3"] <- DGP_flow_sdm(z = Z_ge, delta = delta,  rho = rho[1],
               W_o = as.matrix(W_ge_o), 
               seed = 123, sigma = 1, message = F,
               model = "model_3")

flows_ge[, "y_2"] <- DGP_flow_sdm(z = Z_ge, delta = delta,  rho = rho[1],
               W_d = as.matrix(W_ge_d), 
               seed = 123, sigma = 1, message = F,
               model = "model_2")

flows_ge[, "y_1"] <- DGP_flow_sdm(z = Z_ge, delta = delta,
               seed = 123, sigma = 1, message = F,
               model = "model_1")

flows_ge_od[, "y_1"] <- DGP_flow_sdm(z = Z_ge_od, delta = delta[-c(2, 5, 8)],
               seed = 123, sigma = 1, message = F,
               model = "model_1")
```

```{r, echo = F}
Y_ge_9 <- matrix(flows_ge$y_9, n_ge, n_ge)
Y_ge_8 <- matrix(flows_ge$y_8, n_ge, n_ge)
Y_ge_7 <- matrix(flows_ge$y_7, n_ge, n_ge)
Y_ge_6 <- matrix(flows_ge$y_6, n_ge, n_ge)
Y_ge_5 <- matrix(flows_ge$y_5, n_ge, n_ge)
Y_ge_4 <- matrix(flows_ge$y_4, n_ge, n_ge)
Y_ge_3 <- matrix(flows_ge$y_3, n_ge, n_ge)
Y_ge_2 <- matrix(flows_ge$y_2, n_ge, n_ge)
Y_ge_1 <- matrix(flows_ge$y_1, n_ge, n_ge)
Y_ge_od_1 <- matrix(flows_ge_od$y_1, n_ge, n_ge)
```

```{r}
Z_usa <- cbind(1, flows_ge$vec_In, 
               flows_usa$x_d, flows_usa$x_o, flows_usa$x_i, 
              flows_usa$lagged_x_d, flows_usa$lagged_x_o, flows_usa$lagged_x_i, 
              flows_usa$g)

Z_usa_od <- cbind(1, flows_usa_od$x_d, flows_usa_od$x_o, flows_usa_od$x_i, 
              flows_usa_od$lagged_x_d, flows_usa_od$lagged_x_o, flows_usa_od$lagged_x_i, 
              flows_usa_od$g)


flows_usa[, "y_9"] <- DGP_flow_sdm(z = Z_usa, delta = delta,  rho = rho,
               W_d = as.matrix(W_usa_d), 
               W_o = as.matrix(W_usa_o), 
               W_w = as.matrix(W_usa_w), 
               seed = 123, sigma = 1, message = F,
               model = "model_9")

flows_usa[, "y_8"] <- DGP_flow_sdm(z = Z_usa, delta = delta,  rho = rho[1:2],
               W_d = as.matrix(W_usa_d), 
               W_o = as.matrix(W_usa_o), 
               W_w = as.matrix(W_usa_w), 
               seed = 123, sigma = 1, message = F,
               model = "model_8")

flows_usa[, "y_7"] <- DGP_flow_sdm(z = Z_usa, delta = delta,  rho = rho[1:2],
               W_d = as.matrix(W_usa_d), 
               W_o = as.matrix(W_usa_o), 
               seed = 123, sigma = 1, message = F,
               model = "model_7")

flows_usa[, "y_6"] <- DGP_flow_sdm(z = Z_usa, delta = delta,  rho = rho[1],
               W_d = as.matrix(W_usa_d), 
               W_o = as.matrix(W_usa_o),
               W_w = as.matrix(W_usa_w), 
               seed = 123, sigma = 1, message = F,
               model = "model_6")

flows_usa[, "y_5"] <- DGP_flow_sdm(z = Z_usa, delta = delta,  rho = rho[1],
               W_d = as.matrix(W_usa_d), 
               W_o = as.matrix(W_usa_o),
               seed = 123, sigma = 1, message = F,
               model = "model_5")

flows_usa[, "y_4"] <- DGP_flow_sdm(z = Z_usa, delta = delta,  rho = rho[1],
               W_w = as.matrix(W_usa_w), 
               seed = 123, sigma = 1, message = F,
               model = "model_4")

flows_usa[, "y_3"] <- DGP_flow_sdm(z = Z_usa, delta = delta,  rho = rho[1],
               W_o = as.matrix(W_usa_o), 
               seed = 123, sigma = 1, message = F,
               model = "model_3")

flows_usa[, "y_2"] <- DGP_flow_sdm(z = Z_usa, delta = delta,  rho = rho[1],
               W_d = as.matrix(W_usa_d), 
               seed = 123, sigma = 1, message = F,
               model = "model_2")

flows_usa[, "y_1"] <- DGP_flow_sdm(z = Z_usa, delta = delta,
               seed = 123, sigma = 1, message = F,
               model = "model_1")

flows_usa_od[, "y_1"] <- DGP_flow_sdm(z = Z_usa_od, delta = delta[-c(2, 5, 8)],
               seed = 123, sigma = 1, message = F,
               model = "model_1")
```

```{r, echo = F}
Y_usa_9 <- matrix(flows_usa$y_9, n_usa, n_usa)
Y_usa_8 <- matrix(flows_usa$y_8, n_usa, n_usa)
Y_usa_7 <- matrix(flows_usa$y_7, n_usa, n_usa)
Y_usa_6 <- matrix(flows_usa$y_6, n_usa, n_usa)
Y_usa_5 <- matrix(flows_usa$y_5, n_usa, n_usa)
Y_usa_4 <- matrix(flows_usa$y_4, n_usa, n_usa)
Y_usa_3 <- matrix(flows_usa$y_3, n_usa, n_usa)
Y_usa_2 <- matrix(flows_usa$y_2, n_usa, n_usa)
Y_usa_1 <- matrix(flows_usa$y_1, n_usa, n_usa)
Y_usa_od_1 <- matrix(flows_usa_od$y_1, n_usa, n_usa)
```



# Data Vizualization #

## List of origins and destinations coincide 

```{r}
mtq_mob <- getLinkLayer(
  x = spdf_au, 
  xid = "NOM", 
  df = flows_au, 
  dfid = c("origin","dest")
)
```

We discretize the variable *real_Y*:
```{r}
breaks <- quantile(flows_au$real_Y)
flows_au$real_Y_discret <- cut(flows_au$real_Y, breaks,
                            include.lowest = T)
```

We plot all the flows.

```{r}
# pdf("figures/flows.pdf", width = 6, height = 6)
par(bg = "grey25", oma = c(0, 0, 0, 0),
    mar = c(0, 0, 0, 0), mai = c(0, 0, 0, 0))
# plot municipalities 
plot(spdf_au, col = "grey13", border = "grey25", 
     bg = "grey25", lwd = 0.5)
# plot graduated links
gradLinkTypoLayer(
  x = mtq_mob, 
  xid = c("origin","dest"),
  df = flows_au, 
  dfid = c("origin","dest"),
  var = "real_Y", 
  breaks = breaks,
  lwd = c(1, 4, 8, 16),
  var2 = "real_Y_discret", 
  legend.var.pos = "left",
  legend.var.title.txt = "Nb. of\nTrade",
) 

# map layout
layoutLayer(title = "Trades", 
            sources = "Simulated data",  
            author = paste0("cartography ", packageVersion("cartography")), 
            frame = FALSE, col = "grey25", coltitle = "white",
            tabtitle = TRUE)
# dev.off()
```


##  List of origins and destinations do not coincide 

We first have to create a Spatial object containing both origin and destinations spatial units.
```{r}
sf_mig_o_d <- rbind(africa[, "NOM"], 
                    europe[, "NOM"])
```

```{r}
mtq_mob <- getLinkLayer(
  x = sf_mig_o_d, 
  xid = "NOM", 
  df = flows_mig, 
  dfid = c("origin","dest")
)
```

We discretize the variable $y_9$:
```{r}
breaks <- quantile(flows_mig$y_9, 
                   c(0, 0.9, 0.925, 0.95, 0.975, 1))
flows_grid$y_9_discret <- cut(flows_grid$y_9, breaks,
                            include.lowest = T)
```

We plot the largest flows only.

```{r}
par(bg = "grey25", oma = c(0, 0, 0, 0),
    mar = c(0, 0, 0, 0), mai = c(0, 0, 0, 0))
# plot municipalities
plot(spdf_grid_o_d, col = "grey13", border = "grey25", 
     bg = "grey25", lwd = 0.5)
# plot graduated links
gradLinkTypoLayer(
  x = mtq_mob, 
  xid = c("origin","dest"),
  df = flows_grid, 
  dfid = c("origin","dest"),
  var = "y_9", 
  breaks = breaks[2:6],
  lwd = c(1, 4, 8, 16),
  var2 = "y_9_discret", 
  legend.var.pos = "left",
  legend.var.title.txt = "Nb. of\nTrade",
) 

# map layout
layoutLayer(title = "Trades", 
            sources = "Simulated data",  
            author = paste0("cartography ", packageVersion("cartography")), 
            frame = FALSE, col = "grey25", coltitle = "white",
            tabtitle = TRUE)
```
# Non spatial modelling #

## Gravity model ##

The form of the classical gravity model is $Y = \alpha1_{N}+X_o\beta_o+X_d\beta_d+\gamma g + \epsilon$. To fit this model with **R**, we propose two options:

* We implement the formulas proposed by LeSage and Pace (2008) which avoid to store the full vectors for the explanatory variables by using the Kronecker product properties.

* Use the function *lm()* applied to the vectorized form of the data set. 


## LeSage and Pace (2008) estimation ##

LeSage and Pace (2008) show that we can avoid to store the flows data by using the property of the Kroneker product in the space of the regions data. In their paper, they consider the case where $x$ is centered which allows some further simplifications in the resolution of the problem. We call this function *gravity_model()*. It takes as input arguments : 

```{bash, eval = F}
gravity_model(x, Y, G, ind_d = NULL, ind_o = NULL) 
```

* **x**, a **data.frame** or a matrix with explanatory variables observed on the $n$ geographical sites.
* **Y**, the matrix of flows of size $n \times n$,
* **G**, the matrix of distances of size $n \times n$,
* **ind_d**, the indices of the variables in **x** which will be used at the destination,
* **ind_o**, the indices of the variables in **x** of the variables used at the origin.


```{r, echo = T}
source("./R/gravity_model_2.R")
```

## Applications ##

### With the Australian simulated data ###

```{r}
gravity_model(x = as.matrix(spdf_au@data$x), Y = Y_au_od_1, 
              G = G_au, lagged = T, centered = T, w = w_au,
              intra_x = F)
```

We compare the results with the ones obtained with the function *lm()* :

```{r}
gravity_flows <- lm(y_1 ~ x_d + lagged_x_d + x_o + lagged_x_o + g, 
                    data = flows_au_od)
```

The function *summary()* gives also the standard errors of the estimated coefficients and the results of the t-test. It also gives the values of the $R^2$. 

```{r}
summary(gravity_flows)
```

**Remark 1:** Unsurprisingly, we find the same values of the estimates for $\beta_o$, $\beta_d$ and $\gamma$ than those obtained with the function *gravity_model()*. The estimate of the intercept is different because the data have been centered. 

**Remark 2:** to compute the estimates with the *lm()* function, the user needs to work with the full matrix of size $N \times 2p$ where $p$ is the number of explanatory variable. 

### With the Australian simulated data with intra effect ###

```{r}
gravity_model(x = as.matrix(spdf_au@data$x), Y = Y_au_1, 
              G = G_au, lagged = T, centered = F, w = w_au,
                intra_x = T)
```

We compare the results with the ones obtained with the function *lm()* :

```{r}
gravity_flows <- lm(y_1 ~ vec_In + x_d + x_o + x_i + 
                      lagged_x_d + lagged_x_o + lagged_x_i + g, 
                    data = flows_au)
summary(gravity_flows)
```

### With the Australian real data ###

```{r}
gravity_model(x = log(as.matrix(spdf_au@data[, 
                      c("wage", "pop", "age")])), 
              Y = log(au_flows), ind_d = c(2, 3), 
              ind_o = c(1, 2), 
              G = G_au, lagged = T, centered = F, w = w_au,
              intra_x = F)
```

We compare the results with the ones obtained with the function *lm()* :

```{r}
gravity_real_flows <- lm(log(real_Y) ~ log(pop_d) + log(age_d) + 
                          lagged_ln_pop_d + lagged_ln_age_d + 
                           log(wage_o) + log(pop_o) +
                           lagged_ln_wage_o + lagged_ln_pop_o + g, 
                         data = flows_au_od)
summary(gravity_real_flows)
```

Intraregionnal model:
```{r}
gravity_model(x = log(as.matrix(spdf_au@data[, 
                      c("wage", "pop")])), 
              Y = log(au_flows), G = G_au, lagged = T, w = w_au,
              intra_x = T)
```

We compare the results with the ones obtained with the function *lm()* :

```{r}
gravity_real_flows <- lm(log(real_Y) ~ vec_In + 
                           ln_wage_d + ln_pop_d  + 
                           lagged_ln_wage_d + lagged_ln_pop_d  +
                           ln_wage_o + ln_pop_o + 
                           lagged_ln_wage_o + lagged_ln_pop_o +
                           ln_wage_i + ln_pop_i + 
                           lagged_ln_wage_i + lagged_ln_pop_i + g, 
                         data = flows_au)
summary(gravity_real_flows)
```


Computational time test : 




### Comparison of computationnal ###

```{r}
microbenchmark::microbenchmark(
  # australia
  gravity_model(x = as.matrix(spdf_au@data$x), 
                  Y = Y_au_od_1, G = G_au, centered = T),
  gravity_model(x = as.matrix(spdf_au@data$x), 
                  Y = Y_au_od_1, G = G_au),
  lm(y_1 ~ x_d + x_o + g, data = flows_au_od),
  gravity_model(x = as.matrix(spdf_au@data$x), 
                  Y = Y_au_1, G = G_au, intra_x = T),
  # germany
  gravity_model(x = as.matrix(spdf_ge@data$x), 
                   Y = Y_ge_od_1, G = G_ge, centered = T),
  gravity_model(x = as.matrix(spdf_ge@data$x), 
                   Y = Y_ge_od_1, G = G_ge),
  lm(y_1 ~ x_d + x_o + g, data = flows_ge),
  gravity_model(x = as.matrix(spdf_ge@data$x), 
                   Y = Y_ge_od_1, G = G_ge, intra_x = T),
  # usa
  gravity_model(x = as.matrix(spdf_usa@data$x), 
                Y = Y_usa_od_1, G = G_usa, centered = T),
  gravity_model(x = as.matrix(spdf_usa@data$x), 
                Y = Y_usa_od_1, G = G_usa),
  lm(y_1 ~ x_d + x_o + g, data = flows_usa),
  gravity_model(x = as.matrix(spdf_usa@data$x), intra_x = T, 
                Y = Y_usa_od_1, G = G_usa),
  times = 1000L
)
```




# Spatial Modelling # 

When the number of flows $N$ is equal to $n_o\times n_d$, this implies some simplifications in the computations. However, this is not always the case in practice. That is why we consider the two options :

* $N =n_o\times n_d$
* $N < n_o\times n_d$ 

## Spatial Autoregressive Interaction Models when $N = n_o\times n_d$ ##

We use the Bayesian SAR method for estimating the parameters. Before estimating the parameters in the SAR flows model, we have to create intermediate functions :

```{bash, eval = F}
ftrace1(w, method = "exact", miter = 10, riter = 50)
```

* *ftrace1()*, which computes the traces of the spatial weight matrices $W$, $W^2$, $W^3$, ..., $W^{miter}$,
* *fodet1()*, which computes the jacobian matrix in the case of model (9), i.e. the model with the 3 spatial weight matrices $W_o$, $W_d$, $W_w$
* *lndetmc()*, which computes the jacobian matrix in the case of a model with a single spatial weight matrix,
* *c_sarf()*, which computes the log likelihood conditionnally to $\rho$.

### Traces of the spatial weight matrix ###

We first code the function **ftrace1()** which computes the traces of $W$, $W^2$, $W^3$, ..., $W^{miter}$.  The two possible methods are **"exact"** (based on the computation of $W$, $W^2$, $W^3$, ..., $W^{miter}$) or **"approx"** (based on an MCMC approximation, Barry and Pace, 99). The argument **miter** corresponds to the desired maximum order trace and **riter** the maximum number of iterations used to estimate the trace.

```{r, echo = F}
source("./R/ftrace1.R")
```

Example: we compute the traces on the first 10 powers of the spatial weigh matrix. Here we do not use an approximation because the size of the matrix is small

```{r}
(traces <- ftrace1(w_au))
```

By using the algorithm proposed by Barry and Pace (1999), the approximated traces are equal to:

```{r}
(traces_approx <- ftrace1(w_au, method = "approx", miter = 10, riter = 50000))
```


### Computation of the determinant ###

#### General case with $W_o$, $W_d$, $W_w$

To compute the log determinant in the case of the full model (model 9), we code the function **fodet1()**. The input arguments are: 

```{bash, eval = F}
fodet1(parms, traces, n)
```

* **parms**, a **numeric** vector containing $\rho_1$, $\rho_2$, $\rho_3$, 
* **traces**, a **numeric** vector containing the estimated traces of $W$, $W^2$, ...,$W^{miter}$, 
* **n**, the sample size. 

```{r, echo = T}
source("./R/fodet1.R")
```


#### Case with only one spatial weight matrix ($W_o$, $W_d$ or $W_w$)

In the particular case where there is a single spatial weight matrix (model 2 to 6 in Lesage and Pace, 2008), the algorithm is much simpler because the computation of $Ln|I_N-\rho W_S|$ where $S=o,d,w,o+d,o+d+w$ can be expressed directly as a function of the Jacobian of $W$. First, the user has to compute the trace of the matrix $W$ by using the function *ftrace1()* and then compute the log determinant by using the function *lndetmc()*.

The function takes as input arguments: 

```{bash, eval = F}
lndetmc(parms, traces, n)
```

* **parms**, a scalar usually corresponding to the value of $\rho$,
* **traces** a vector of numeric corresponding to the eigen values of spatial weight matrix $W$,
* **n**, an integer, the size of the sample.


```{r, echo = T}
source("./R/lndetmc.R")
```

In the case of a small matrix, we use the exact values of the traces of $W$, $W^2$, $W^3$, ...

```{r}
lndetmc(0.25, traces, n_au)
```

In the case of a larger matrix, one can use the approximation:

```{r}
lndetmc(0.25, traces_approx, n_au)
```

#### Case of two spatial weight matrices 

One can use formula (29) of Lesage and Pace (2008) to sum the log determinants of the two spatial weight matrices. For example, if $\rho_o=0.4$ and $\rho_d=0.2$, then the log determinant is equal to:

```{r}
lndetmc(0.4, traces_approx, n_au) + lndetmc(0.2, traces_approx, n_au)
```



### Evaluation of the log likelihood conditionnally to $\rho$  ###

The function *c_sarf()* takes as arguments:

```{bash, eval = F}
c_sarf(rho, sige, Q, traces, n, nvars)
```

* **rho**, a vector containing the estimated values of $\rho_d$, $\rho_d$, $\rho_w$, 
* **sige**, the value of $\sigma^2$
* **Q**, cross-product matrix of the various component residuals
* **traces** a vector of numeric corresponding to the eigenvalues of the spatial weight matrix $W$,
* **n**, an integer, the sample size.



```{r, echo = T}
source("./R/c_sarf.R")
```


### Function *sar_flow()* model ###

It takes as input arguments : 
  
```{bash, eval = F}
sar_flow(x, Y, G, w, ind_d = NULL, ind_o = NULL, model = "model_9")
```

* **x**, a **data.frame** or a matrix with explanatory variables observed on the $n$ geographical sites.
* **Y**, the matrix of flows of size $n \times n$,
* **G**, the matrix of distances of size $n \times n$,
* **w**, the spatial weight matrix of size $n \times n$,
* **ind_d**, the indices of the variables in **x** which will be used at the destination,
* **ind_o**, the indices of the variables in **x** of the variables used at the origin.


```{r, echo = F}
source("./R/sar_flow.R")
```

### Function *sar_flow_2()* model ###

In the case when $N \leq n^2$, users have to present the data in vectorized form. It is also possible to use this function when $N = n^2$,

It takes as input arguments : 
  
* **x**, a **data.frame** or a matrix with explanatory variable observed on the $N$ flows.
* **Y**, the vector of flows of size $N$,
* **g**, the vector of distances of size $N$,
* **W_d**, spatial weight matrix of size $N \times N$,
* **W_o**, spatial weight matrix of size $N \times N$,
* **W_w**, spatial weight matrix of size $N \times N$,
* **ind_d**, the indices of the variables in **x** which will be used at the destination,
* **ind_o**, the indices of the variables in **x** used at the origin.

```{bash, eval = F}
sar_flow_2(x, y, g, W_d, W_o, W_w, 
           ind_d = NULL, ind_o = NULL, model = "")
```

```{r, echo = F}
source("./R/sar_flow_2.R")
```


### Application to the toy data

#### Model 2

##### Bayesian estimation

We evaluate model 2 when $Y$ corresponds to the DGP used with model 2. <!-- We choose to include characteristics $x_1$ only at destination and $x_2$ only at origin.  -->
  
We compare the estimates obtained when we used the method $N= n^2$ and when we used the method $N\leq n^2$ .

```{r, eval = F}
system.time(sar_simu_2_method1 <- sar_flow(x = matrix(au_df$x, 
                                nrow = n_au, dimnames = list(1:n_au, "x")), 
                                Y = Y_au_2, 
                                G = G_au, 
                                w = w_au,  
                                model = "model_2",
                                lagged = T) 
)
sar_simu_2_method1
```


```{r, echo= F, eval = T}
load("sar_simu_2_sdm.RData")
sar_simu_2_method1
```

Both methods give approximatly the same estimates. The first one is obtained in 6.5s when the second is obtained in 54s.  

```{r, eval = F}
system.time(sar_simu_2_method2 <- sar_flow_2(x = flows_au[, c("x_d", "W_dx_d", 
                                                                "x_o", "W_ox_o")], 
                                             y = flows_au$y_2, 
                                             g = flows_au$g, 
                                             W_d = W_au_d,  
                                             model = "model_2", centered = F) 
)
sar_simu_2_method2
```

```{r, echo= F, eval = T}
load("sar_simu_2_sdm.RData")
sar_simu_2_method2
```

```{r, echo= F, eval = F}
save(sar_simu_2_method1, sar_simu_2_method2, file = "sar_simu_2_sdm.RData")
```


**Computationnal time of the Spatial Interaction Durbin Model 2** according to the size of the samples:

```{r, eval = F, echo = F}
time_au_bayes_1 <- system.time(sar_simu_2_method1 <- sar_flow(
  x = matrix(au_df$x, nrow = n_au, dimnames = list(1:n_au, "x")), 
  Y = Y_au_2, G = G_au, w = w_au, model = "model_2", lagged = T) 
)
time_au_bayes_2 <- system.time(sar_simu_2_method2 <- sar_flow_2(
  x = flows_au[, c("x_d", "W_dx_d", "x_o", "W_ox_o")], 
  y = flows_au$y_2, g = flows_au$g, W_d = W_au_d, 
  model = "model_2", centered = F) 
)

time_ge_bayes_1 <- system.time(sar_simu_2_ge_method1 <- sar_flow(
  x = matrix(ge_df$x, nrow = n_ge, dimnames = list(1:n_ge, "x")), 
  Y = Y_ge_2, G = G_ge, w = w_ge, model = "model_2", lagged = T) 
)
time_ge_bayes_2 <- system.time(sar_simu_2_ge_method2 <- sar_flow_2(
  x = flows_ge[, c("x_d", "W_dx_d", "x_o", "W_ox_o")], 
  y = flows_ge$y_2, g = flows_ge$g, W_d = W_ge_d, 
  model = "model_2", centered = F) 
)

time_usa_bayes_1 <- system.time(sar_simu_2_usa_method1 <- sar_flow(
  x = matrix(usa_df$x, nrow = n_usa, dimnames = list(1:n_usa, "x")), 
  Y = Y_usa_2, G = G_usa, w = w_usa, model = "model_2", lagged = T) 
)
time_usa_bayes_2 <- system.time(sar_simu_2_usa_method2 <- sar_flow_2(
  x = flows_usa[, c("x_d", "W_dx_d", "x_o", "W_ox_o")], 
  y = flows_usa$y_2, g = flows_usa$g, W_d = W_usa_d, 
  model = "model_2", centered = F) 
)
```

```{r, echo = F, eval = F}
save(time_au_bayes_1, time_ge_bayes_1, time_usa_bayes_1, 
     time_au_bayes_2, time_ge_bayes_2, time_usa_bayes_2,
     file = "time_bayes_mod2.RData")
```

```{r, echo = F}
load("time_bayes_mod2.RData")
```

```{r, echo = F}
(time_bayesian_sdm <- data.frame(matrix = c(time_au_bayes_1[3], time_ge_bayes_1[3], 
                                      time_usa_bayes_1[3]),
                           vector = c(time_au_bayes_2[3], time_ge_bayes_2[3],
                                      time_usa_bayes_2[3]),
                           row.names = c("au", "ge", "usa")))  
```



##### Comparaison with the log-likelihood estimation

We compare the results with the *lagsarlm()* function and we remark that we obtain similar results :(results are obtained in less than 1s).

```{r, message = F}
result_lagsarlm <- lagsarlm(y_2 ~ x_d + W_dx_d + x_o + x_i +  W_ox_o + g, 
                            data = flows_au, 
                            mat2listw(W_au_d))
summary(result_lagsarlm)
```


**Computational time** with respect to the size of the samples:

```{r, echo = F}
time_au_lagsarlm <- system.time(lagsarlm(y_2 ~ x_d + W_dx_d + x_o + W_ox_o + g, 
                      data = flows_au, mat2listw(W_au_d)))
time_ge_lagsarlm <- system.time(lagsarlm(y_2 ~ x_d + W_dx_d + x_o + W_ox_o + g, 
                      data = flows_ge, mat2listw(W_ge_d)))
time_usa_lagsarlm <- system.time(lagsarlm(y_2 ~ x_d + W_dx_d + x_o + W_ox_o + g, 
                      data = flows_usa, mat2listw(W_usa_d)))
```

```{r, echo = F}
(time_lagsarlm_sdm <- data.frame(vector = c(time_au_lagsarlm[3], 
                                            time_ge_lagsarlm[3],
                                            time_usa_lagsarlm[3]),
                                 row.names = c("au", "ge", "usa")))  
```

##### Comparaison with the S2SLS estimation

We remark that we canno't use S2SLS method because of inversion problems.

```{r, eval = F}
result_s2sls<- stsls(y_2 ~ x_d + W_dx_d + x_o + W_ox_o + g, 
                           data = flows_au, 
                           mat2listw(W_au_d))
summary(result_s2sls)
```

We coded the S2SLS for a general spatial model flow (model 9). The codes are in the *s2sls_flow()* function which takes as input arguments : 

```{bash, eval = F}
s2sls_flow(x_d, x_o, y, g, W_d = NULL, W_o = NULL, W_w = NULL)
```

* **x_d**, a **data.frame** or a matrix with the destination explanatory variables observed on the $N$ flows.
* **x_o**, a **data.frame** or a matrix with the origin explanatory variables observed on the $N$ flows.
* **y**, the vector of flows of size $N$,
* **g**, the vector of distances of size $N$,
* **W_d**, the spatial weight destination matrix of size $N \times N$,
* **W_o**, the spatial weight origin matrix of size $N \times N$,
* **W_w**, the spatial weight matrix of size $N \times N$,


```{r, echo = F}
source("./R/s2sls_flow.R")
```

```{r}
(sar_simu_2_sls <- s2sls_flow(x_d = flows_au[, c("x_d", "W_dx_d")],
                              x_o = flows_au[, c("x_o", "W_ox_o")],
                              y = flows_au$y_2, 
                              g = flows_au$g, 
                              instru_x_d = c(F, T),
                              instru_x_o = c(F, F),
                              W_d = W_au_d)) 
```

**Computational time** with respect to the size of the samples:

```{r, echo = F}
time_au_stsls <- system.time(s2sls_flow(
  x_d = flows_au[, c("x_d", "W_dx_d")],
  x_o = flows_au[, c("x_o", "W_ox_o")],
  y = flows_au$y_2, 
  g = flows_au$g, 
  instru_x_d = c(F, T),
  instru_x_o = c(F, F),
  W_d = W_au_d))

time_ge_stsls <- system.time(s2sls_flow(
  x_d = flows_ge[, c("x_d", "W_dx_d")],
  x_o = flows_ge[, c("x_o", "W_ox_o")],
  y = flows_ge$y_2, 
  g = flows_ge$g, 
  instru_x_d = c(F, T),
  instru_x_o = c(F, F),
  W_d = W_ge_d))

time_usa_stsls <- system.time(s2sls_flow(
  x_d = flows_usa[, c("x_d", "W_dx_d")],
  x_o = flows_usa[, c("x_o", "W_ox_o")],
  y = flows_usa$y_2, 
  g = flows_usa$g, 
  instru_x_d = c(F, T),
  instru_x_o = c(F, F),
  W_d = W_usa_d))
```

```{r, echo = F}
(time_stsls_sdm <- data.frame(vector = c(time_au_stsls[3], 
                                            time_ge_stsls[3],
                                            time_usa_stsls[3]),
                                 row.names = c("au", "ge", "usa")))  
```

#### Model 9

##### Bayesian estimation 

We evaluate model 9 when $Y$ corresponds to the DGP used with model 9 by using the full matrix. Computation was done in 376s by using the full matrix.

```{r, eval = F, echo = F}
system.time(sar_simu_9_method1 <- sar_flow(x = matrix(au_df$x, 
                            nrow = n_au, dimnames = list(1:n_au, "x")), 
                                     Y = Y_au_9, 
                                     G = G_au, 
                                     w = w_au,  
                                     model = "model_9",
                                     lagged = T) 
)
```


```{r, echo = F}
load("sar_simu_9_sdm.RData")
sar_simu_9_method1
```

We evaluate model 9 when $Y$ corresponds to the DGP used with model 9 by using the second method. Computation was done in 335s.

```{r, eval = F}
system.time(sar_simu_9_method2 <- sar_flow_2(x = flows_au[, c("x_d", "W_dx_d", 
                                                                "x_o", "W_ox_o")], 
                                     y = flows_au$y_9, 
                                     g = flows_au$g, 
                                     W_d = W_au_d, W_o = W_au_o, W_w = W_au_w, 
                                     model = "model_9", centered = F) 
)
```

```{r, echo = F}
sar_simu_9_method2
```

```{r, echo = F, eval = F}
save(sar_simu_9_method1, sar_simu_9_method2, file = "sar_simu_9_sdm.RData")
```


**Computationnal time of the Spatial Interaction Durbin Model 2** according to the size of the samples:

```{r, eval = F, echo = F}
time_au_bayes_1 <- system.time(sar_simu_9_method1 <- sar_flow(
  x = matrix(au_df$x, nrow = n_au, dimnames = list(1:n_au, "x")), 
  Y = Y_au_9, G = G_au, w = w_au, model = "model_9", lagged = T) 
)
time_au_bayes_2 <- system.time(sar_simu_9_method2 <- sar_flow_2(
  x = flows_au[, c("x_d", "W_dx_d", "x_o", "W_ox_o")], 
  y = flows_au$y_9, g = flows_au$g, 
  W_d = W_au_d, W_o = W_au_o, W_w = W_au_w, 
  model = "model_9", centered = F) 
)

time_ge_bayes_1 <- system.time(sar_simu_9_ge_method1 <- sar_flow(
  x = matrix(ge_df$x, nrow = n_ge, dimnames = list(1:n_ge, "x")), 
  Y = Y_ge_9, G = G_ge, w = w_ge, model = "model_9", lagged = T) 
)
time_ge_bayes_2 <- system.time(sar_simu_9_ge_method2 <- sar_flow_2(
  x = flows_ge[, c("x_d", "W_dx_d", "x_o", "W_ox_o")], 
  y = flows_ge$y_9, g = flows_ge$g, 
  W_d = W_ge_d, W_o = W_ge_o, W_w = W_ge_w, 
  model = "model_9", centered = F) 
)

time_usa_bayes_1 <- system.time(sar_simu_9_usa_method1 <- sar_flow(
  x = matrix(usa_df$x, nrow = n_usa, dimnames = list(1:n_usa, "x")), 
  Y = Y_usa_9, G = G_usa, w = w_usa, model = "model_9", lagged = T) 
)
time_usa_bayes_2 <- system.time(sar_simu_9_usa_method2 <- sar_flow_2(
  x = flows_usa[, c("x_d", "W_dx_d", "x_o", "W_ox_o")], 
  y = flows_usa$y_9, g = flows_usa$g, 
  W_d = W_usa_d, W_o = W_usa_o, W_w = W_usa_w, 
  model = "model_9", centered = F) 
)
```

```{r, echo = F, eval = F}
save(time_au_bayes_1, time_ge_bayes_1, time_usa_bayes_1, 
     time_au_bayes_2, time_ge_bayes_2, time_usa_bayes_2,
               file = "time_bayes_mod_9.RData")
```

```{r, echo = F, eval = T}
load("time_bayes_mod_9.RData")
```

```{r, eval = T}
(time_bayesian_sdm <- data.frame(matrix = c(time_au_bayes_1[3], time_ge_bayes_1[3], 
                                      time_usa_bayes_1[3]),
                           vector = c(time_au_bayes_2[3], time_ge_bayes_2[3],
                                      time_usa_bayes_2[3]),
                           row.names = c("au", "ge", "usa")))  
```


##### S2SLS estimation

```{r}
(sar_simu_9_sls <- s2sls_flow(x_d = flows_au[, c("x_d", "W_dx_d")],
                              x_o = flows_au[, c("x_o", "W_ox_o")],
                              y = flows_au$y_9, 
                              g = flows_au$g,
                              instru_x_d = c(F, T),
                              instru_x_o = c(F, F),
                              W_o = W_au_o, 
                              W_d = W_au_d,
                              W_w = W_au_w)) 

```


# Interpreting the results #

## Understanding the decomposition of impacts

With the bayesian estimates obtained below in the model 9, one could obtain the predictions by using for example the IC formula (Goulard et al, 2017). 

```{r}
delta_estimates <- sar_simu_9_method1[c("(intercept)", "x_d", "x_o", 
                                "lagged_x_d", "lagged_x_o", "g"), "mean" ]
#delta_estimates <- c(0, 1, 0.5, 0, 0, -0.5 )
rho_estimates <- sar_simu_9_method1[c("rho_d", "rho_o", "rho_w"), "mean" ]
#rho_estimates <- c(0.4, 0.4, -0.16)
A_W <- solve(diag(n_au ^ 2) - rho_estimates[1] * W_au_d -
                   rho_estimates[2] * W_au_o - rho_estimates[3] * W_au_w)
Y_predict <- A_W %*% Z_au %*% delta_estimates
```

Lesage and Pace (2004) illustrate the concept of spillovers in the general case a SAR model. They look the effect on the predictions when they increase by one unit the explanatory variable for one observation. Here we increase the variable $x$ by one unit in the observation R3. For doing that we create a function which permits to transform the data.frame.

```{r}
epsilon_when_change_one_unit <- function (which_unit, x, g, W_d, W_o, A_W,
                                          delta_estimates, Y_predict, 
                                          change_xo = T, change_xd = T) {
  n <- length(x)
  N <- n * n
  add_1 <- numeric(n)
  add_1[which_unit] <- 1
  x_changed <- x + add_1
  if (change_xo) {
    x_o <- kronecker(x_changed, rep(1, n))
  } else {
    x_o <- kronecker(x, rep(1, n))  
  }
  if (change_xd) {
    x_d <- kronecker(rep(1, n), x_changed) 
  } else {
    x_d <- kronecker(rep(1, n), x) 
  }
  Z_changed <- cbind(rep(1, N), x_d, x_o, W_d %*% x_d, W_o %*% x_o, g)
  Y_predict_changed <- A_W %*% Z_changed %*% delta_estimates
  return(as.numeric(Y_predict_changed - Y_predict))
}
```

Now, we look at the differences obtained between the predictions and we can observe that when  changing only observation R3, it impacted all the flows. 

```{r}
matrix(epsilon_when_change_one_unit(3, au_df$x, flows_au$g,
                                    as.matrix(W_au_d), as.matrix(W_au_o),
                                    A_W, delta_estimates, Y_predict), 8, 8, byrow = T)
```

Lesage and Thomas-Agnan (2014) propose to summarize the impacts into 4 main groups :

* The OD which consists in summing up all the flows which have $R3$ as origin (and excluding the intra) which correspond to the 3rd row,
* The DE which consists in summing up all the flows which have $R3$ as destination (and excluding the intra) which correspond to the 3rd column,
* The intra which consists in the intra flow $R3$ (3rd row, 3rd column) 
* The NE which consists in the rest of the flows 

Then, to have an overview of all the impacts, one can change from one unit all the observations, and then summarize the impacts as seen previously :

```{r}
res <- matrix(0, 5, 4)
for (i in 1:3) {
  
  if (i == 1 | i == 2) {
    change_xo = T
    if (i == 1) 
      change_xd = T
    else 
      change_xd = F
  }
  
  if (i == 3) {
    change_xo = F
    change_xd = T
  }
  
OE <- matrix(0, 8, 8)
DE <- matrix(0, 8, 8)
NE <- matrix(0, 8, 8)
intra <- matrix(0, 8, 8)
total <- matrix(0, 8, 8)
for (k in 1:8) {
  change_Rk <- matrix(epsilon_when_change_one_unit(k, au_df$x, flows_au$g,
                                                   as.matrix(W_au_d), as.matrix(W_au_o),
                                                   A_W, delta_estimates, Y_predict, 
                                                   change_xo = change_xo, 
                                                   change_xd = change_xd), 
                      8, 8, byrow = T)
  intra[k, k] <- intra[k, k] + change_Rk[k, k]
  OE[k, ] <- change_Rk[k, ]
  OE[k, k] <- 0
  DE[, k] <- change_Rk[, k]
  DE[k, k] <- 0  
  NE[!((1:8) %in% k), !((1:8) %in% k)] <- NE[!((1:8) %in% k), !((1:8) %in% k)] + change_Rk[!((1:8) %in% k), !((1:8) %in% k)]
}

# to obtain the final results
res[1:4, i] <- c(mean(OE), mean(DE), mean(intra), mean(NE))
}
res[, 4] <- apply(res[, 2:3], 1, sum)
res[5, ] <- apply(res, 2, sum)
rownames(res) <- c("Origin", "Destination", "Intra",
                   "Network", "Total")
colnames(res) <- c("delta_x", "delta_xo", "delta_xd", "delta_xo + delta_xd")
```

Finally, we obtain that table :
```{r}
res
```

## Computation 

Herby, we try to simplify the computations of the impacts. 

### Computation of $A(W)$

We compute the matrix $A(W) = (I_{N\times N} - \rho_oW_o -\rho_dW_d-\rho_wW_W)^{-1}$. We use the funtion *powerWeights()* which computes the power of matrix.

```{bash, eval = F}
powerWeights(W, rho, order = 250, X, 
   tol = .Machine$double.eps^(3/5))
```

```{r, echo = F}
source("./R/powerWeights.R")
```

## Application on the Model 2 (simulated data)
  
We separate origin and destination estimates :
```{r}
hat_beta_d <- sar_simu_9_method1["x_d", "mean"]
#hat_beta_d <- 1
names(hat_beta_d) <- "x_d"
hat_beta_o <- sar_simu_9_method1["x_o", "mean"]
#hat_beta_o <- 0.5
names(hat_beta_o) <- "x_o"
hat_delta_d <- sar_simu_9_method1["lagged_x_d", "mean"]
#hat_delta_d <- 0
names(hat_delta_d) <- "Wd_xd"
hat_delta_o <- sar_simu_9_method1["lagged_x_o", "mean"]
#hat_delta_o <- 0
names(hat_delta_o) <- "Wo_xo"
```

We compute $A(W)$: 

```{r}
W_hat <- rho_estimates[1] * W_au_d + rho_estimates[2] * W_au_o +
  rho_estimates[3] * W_au_w
AW <- powerWeights(W_hat, 1, order = 250, Diagonal(nrow(W_hat)), 
                   tol = .Machine$double.eps^(3/5))
```

We may need to compute $A(W)\times W$ in the case of the SDM model: 

```{r}
AW_Wo <- AW %*% W_au_o
AW_Wd <- AW %*% W_au_d
```

We need to identify each origin and destination:
```{r}
all_dest <- flows_au[, "dest"] 
all_origin <- flows_au[, "origin"]
```

We coded the function *OE_impact()*, *DE_impact()*, *NE_impact()*, *intra_impact()* which take as argument : 

* **AW**, the matrix $A(W)$,
* **AW_W**, the matrix $A(W) \times W$ if the model is spatial Durbin,
* **all_dest**, a vector which contains the id of the destination in $A(W)$, 
* **all_origin**, a vector which contains the id of the origin in $A(W)$, 


### Origin effect

```{r}
source("./R/OE_impact.R")
```

To get the origin effect:
```{r}
origin_effect <- OE_impact(AW, AW_Wd = AW_Wd, AW_Wo = AW_Wo, 
                           all_dest, all_origin) 
  
(OE <- (origin_effect[[1]] * hat_beta_o + origin_effect[[2]] * hat_beta_d +
       origin_effect[[3]] * hat_delta_o + origin_effect[[4]] * hat_delta_d  ) / n_au^2)
```

### Destination effect

```{r}
source("./R/DE_impact.R")
```

To get the destination effect:
```{r}
destination_effect <- DE_impact(AW, AW_Wd = AW_Wd, AW_Wo = AW_Wo,  
                           all_dest, all_origin) 
  
(DE <- (destination_effect[[1]] * hat_beta_o + destination_effect[[2]] * hat_beta_d +
         destination_effect[[3]] * hat_delta_o + destination_effect[[4]] * hat_delta_d  ) / n_au^2) 
```

### NE effect

```{r}
source("./R/NE_impact.R")
```

To get the NE effect:
```{r}
ne_effect <- NE_impact(AW, AW_Wd = AW_Wd, AW_Wo = AW_Wo,
                           all_dest, all_origin) 
  
(NE <- (ne_effect[[1]] * hat_beta_o + ne_effect[[2]] * hat_beta_d +
         ne_effect[[3]] * hat_delta_o + ne_effect[[4]] * hat_delta_d  ) / n_au^2) 
```

### intra effect

```{r}
source("./R/intra_impact.R")
```

To get the intra effect:
```{r}
intra_effect <- intra_impact(AW, AW_Wd = AW_Wd, AW_Wo = AW_Wo, 
                           all_dest, all_origin) 
  
(intra <- (intra_effect[[1]] * hat_beta_o + intra_effect[[2]] * hat_beta_d +
         intra_effect[[3]] * hat_delta_o + intra_effect[[4]] * hat_delta_d  ) / n_au^2)
```

### Summarise

```{r}
(impacts_mod2 <- cbind(OE, DE, NE, intra))
```



**References**

* LeSage J.P. and Pace R.K. (2008). Spatial econometric modeling of origin-destination flows. Journal of Regional Science, 48(5), 941–-967.

*  Pebesma E.J. and Bivand R.S. (2005). Classes and methods for spatial data in **R**, R News, 5(2), 9--13.

* Thomas-Agnan C. and LeSage J.P. (2014). Spatial Econometric OD-Flow Models. In: Fischer M., Nijkamp P. (eds) Handbook of Regional Science. Springer, Berlin, Heidelberg.  